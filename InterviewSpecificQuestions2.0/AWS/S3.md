## Technical

1. What is Amazon S3?

![Easy](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/simple%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

Amazon S3 is an object storage service provided by AWS. It offers secure, durable, and scalable storage for various types of data, such as documents, images, videos, backups, and logs. S3 is designed to be highly available and accessible from anywhere on the web.

</blockquote>
</details>

---

2. What is an S3 bucket?

![Easy](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/simple%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

An S3 bucket is a container for storing objects in Amazon S3. It acts as a logical unit for organizing and accessing your data. Each bucket must have a globally unique name and can be configured with various settings, permissions, and properties.

</blockquote>
</details>

---

3. How can you upload files to an S3 bucket?

![Easy](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/simple%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

You can upload files to an S3 bucket using the AWS Management Console, AWS CLI (Command Line Interface), or SDKs (Software Development Kits). These tools provide options to upload files individually or in bulk, and you can also set permissions and metadata during the upload process.

</blockquote>
</details>

---

4. How does data consistency work in Amazon S3?

![Medium](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Medium%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

Amazon S3 provides read-after-write consistency for new object uploads and eventual consistency for overwrite and delete operations. This means that when you upload a new object, you can immediately read it and get the latest version. However, if you overwrite or delete an object, it may take some time for the changes to propagate across all S3 servers.

</blockquote>
</details>

---

5. What is an S3 object?

![Easy](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/simple%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

An S3 object is the basic unit of data in Amazon S3. It consists of the data itself and the associated metadata, including a unique key (or filename) within the bucket, the size of the object, and other optional attributes. Objects can be any type of file, such as documents, images, videos, or archives.

</blockquote>
</details>

---

6. How do you control access to your S3 buckets and objects?

![Easy](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/simple%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

Access to S3 buckets and objects can be controlled through a combination of bucket policies, access control lists (ACLs), and IAM (Identity and Access Management) policies. These mechanisms allow you to define fine-grained permissions for different users, groups, or applications accessing your S3 resources.

</blockquote>
</details>

---

7. What is server-side encryption in Amazon S3?

![Medium](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Medium%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

Server-side encryption in Amazon S3 allows you to encrypt data at rest. S3 provides three options for server-side encryption: Amazon S3-managed keys (SSE-S3), AWS Key Management Service (AWS KMS) managed keys (SSE-KMS), and customer-provided keys (SSE-C). These encryption options help protect your data stored in S3.

</blockquote>
</details>

---

8. How will you host a static website using Amazon S3?

![Medium](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Medium%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

You can configure your S3 bucket to function as a static website by enabling static website hosting and specifying the index document and error document. Once configured, your bucket can serve HTML, CSS, JavaScript, and other static files as a web server.

</blockquote>
</details>

---

9. What is the maximum file size you can store in Amazon S3?

![Easy](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/simple%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

In Amazon S3, the maximum file size you can store is 5 terabytes (TB). This limit applies to individual objects within a bucket. However, there is no limit on the total size of a bucket or the number of objects you can store in a bucket.

</blockquote>
</details>

---

10. How can you enable versioning for an S3 bucket?

![Easy](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/simple%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

You can enable versioning for an S3 bucket to preserve multiple versions of an object. With versioning enabled, every write or overwrite creates a new version of the object, allowing you to revert to previous versions if needed. Versioning can be managed through the S3 console, API, or CLI.

</blockquote>
</details>

---

11. What is S3 lifecycle management, and how does it work?

![Medium](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Medium%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

S3 lifecycle management is a feature that automates the transition of objects between different storage classes based on predefined rules. It allows you to optimize storage costs by moving less frequently accessed data to lower-cost storage tiers over time, such as transitioning from Standard to Standard-IA (Infrequent Access) or Glacier.

</blockquote>
</details>

---

12. What is S3 Cross-Region Replication, and how can it be used?

![Medium](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Medium%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

S3 Cross-Region Replication is a feature that automatically replicates objects from one S3 bucket to another bucket in a different AWS region. It helps with disaster recovery, data locality, and compliance requirements. When enabled, S3 asynchronously replicates object changes, such as uploads, modifications, or deletions, to the destination bucket.

</blockquote>
</details>

---

13. What is the difference between S3 Standard, S3 Intelligent-Tiering, and S3 One Zone-IA storage classes?

![Medium](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Medium%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

S3 Standard provides high durability, availability, and low latency for frequently accessed data. S3 Intelligent-Tiering automatically moves objects between Standard and Standard-IA based on their usage patterns. S3 One Zone-IA offers lower-cost storage for infrequently accessed data, but it is stored in a single Availability Zone and lacks the multi-AZ resilience of Standard and Intelligent-Tiering.

</blockquote>
</details>

---

14. What is S3 event notification, and how can it be used?

![Medium](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Medium%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

S3 event notification is a feature that sends notifications when specific events occur in an S3 bucket, such as object creation, deletion, or restoration. These notifications can be delivered to different AWS services, including Lambda functions, SNS (Simple Notification Service) topics, and SQS (Simple Queue Service) queues, enabling you to automate workflows or trigger actions based on S3 events.

</blockquote>
</details>

---

15. How can you share S3 bucket objects with external users or other AWS accounts?

![Medium](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Medium%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

You can share S3 bucket objects with external users or other AWS accounts using a combination of bucket policies and S3 pre-signed URLs. Bucket policies define access permissions, and pre-signed URLs generate time-limited URLs that grant temporary access to specific objects. You can also use AWS IAM roles to grant cross-account access to S3 resources.

</blockquote>
</details>

---

16. What is S3 Select, and how does it work?

![Complex](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Complex%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

S3 Select is a feature that allows you to retrieve only a subset of data from an object by using SQL-like queries. With S3 Select, you can filter, extract, and transform data directly on the server-side, reducing the amount of data transferred over the network and improving query performance. It is useful for analyzing large CSV, JSON, or Parquet files stored in S3.

</blockquote>
</details>

---

17. What are S3 Glacier and S3 Glacier Deep Archive, and when should you use them?

![Medium](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Medium%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

S3 Glacier and S3 Glacier Deep Archive are archival storage classes within Amazon S3. They are designed for long-term data archival and offer extremely low-cost storage with different retrieval options. S3 Glacier is suitable for data that may need to be accessed within minutes to hours, while S3 Glacier Deep Archive is intended for data that may be accessed once or twice a year.

</blockquote>
</details>

---

18. Is it possible to use S3 as a source or destination for data migration or backup?

![Medium](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Medium%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

Yes, S3 can be used as a source or destination for data migration or backup purposes. AWS provides services like AWS Snowball, AWS DataSync, and AWS Storage Gateway that facilitate data transfer between on-premises systems, other cloud providers, and S3. You can also use AWS Backup service to automate backup and recovery of AWS resources, including S3 buckets.

</blockquote>
</details>

---

19. How can you monitor and analyze S3 access and usage?

![Complex](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Complex%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

You can monitor and analyze S3 access and usage using various tools and services. Amazon S3 access logs can be enabled to capture detailed access records, which can be analyzed using Amazon Athena, AWS Glue, or other log analysis tools. Additionally, you can use Amazon CloudWatch metrics and alarms to monitor S3 storage and request metrics in real-time.

</blockquote>
</details>

---

20. What is S3 Object Lock, and how can it be used?

![Medium](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Medium%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

S3 Object Lock is a feature that allows you to enforce a retention period or legal hold on objects stored in S3. It helps ensure that objects remain immutable and unchangeable for a specified duration. Object Lock can be used for compliance, regulatory requirements, and data retention purposes.

</blockquote>
</details>

---

21. What are S3 access points, and why are they useful?

![Complex](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Complex%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

S3 access points are unique hostnames that you can create for your S3 buckets to enforce fine-grained access controls and simplify bucket access management. Access points allow you to delegate access to specific users or applications, enabling better security and reducing the risk of misconfiguration.

</blockquote>
</details>

---

22. How can you optimize performance when accessing S3 data from different regions?

![Complex](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Complex%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

To optimize performance when accessing S3 data from different regions, you can consider using Amazon CloudFront, AWS Global Accelerator, or AWS Direct Connect. CloudFront is a content delivery network that caches S3 content at edge locations, while Global Accelerator and Direct Connect provide dedicated network paths to improve connectivity and reduce latency.

</blockquote>
</details>

---

23. Is it possible to use S3 as a data lake for big data analytics?

![Complex](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Complex%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

Yes, S3 is commonly used as a data lake for big data analytics. It can store vast amounts of structured and unstructured data, and it integrates seamlessly with other AWS services like Amazon Athena, Amazon Redshift Spectrum, and AWS Glue, allowing you to perform advanced analytics and queries on your data.

</blockquote>
</details>

---

24. What is S3 Selective Cross-Region Replication, and how does it work?

![Complex](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Complex%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

S3 Selective Cross-Region Replication is a feature that allows you to selectively replicate specific objects or prefixes from one S3 bucket to another in a different region. It provides more granular control over replication, reducing costs and bandwidth usage compared to replicating the entire bucket. Selective replication is configured using S3 replication rules.

</blockquote>
</details>

---

25. What is S3 Batch Operations, and how can it be used?

![Complex](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Complex%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

S3 Batch Operations is a feature that enables you to perform large-scale operations on objects in S3, such as copying, deleting, or updating metadata. It simplifies and automates the execution of these operations, allowing you to process millions or billions of objects in a single request, significantly reducing the time and effort required.

</blockquote>
</details>

---

26. Is it possible to use S3 as a backup target for AWS RDS databases?

![Complex](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Complex%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

Yes, you can use S3 as a backup target for AWS RDS (Relational Database Service) databases. RDS supports automated backups and manual snapshots, and you can choose to store these backups in an S3 bucket. Storing RDS backups in S3 provides durability, cost efficiency, and flexibility in managing your database backups.

</blockquote>
</details>

---

27. How can you replicate S3 data between AWS accounts or regions?

![Complex](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Complex%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

You can replicate S3 data between AWS accounts or regions using various methods. Cross-account replication allows you to configure one bucket as the source and another bucket in a different account as the destination. Cross-region replication replicates objects between buckets in different regions within the same account. Both options require appropriate permissions and configurations to establish replication.

</blockquote>
</details>

---

28. What is the maximum number of objects you can store in an S3 bucket?

![Complex](https://github.com/revaturelabs/interviewquestions/blob/dev/InterviewSpecificQuestions/ComplexityTags/Complex%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

Amazon S3 does not impose any limit on the number of objects you can store in a bucket. You can store an unlimited number of objects in a bucket, subject to the overall storage capacity limits and performance considerations of S3.

</blockquote>
</details>

---

29. In general, S3 service can have how many buckets?

![Easy](https://github.com/revaturelabs/interviewquestions/blob/dev/ComplexityTags/simple%20(2).svg)

<details>
<summary> <b>Explanation</b> </summary>

<blockquote>

- By default, you can create up to 100 buckets.

</blockquote>
</details>

---

30. What is the minimum and maximum object size that can be stored in S3 bucket?

![Easy](https://github.com/revaturelabs/interviewquestions/blob/dev/ComplexityTags/simple%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

- The minimum size of an object that you can store in S3 is 0 bytes and the maximum size of an object that you can store in S3 is 5 TB.
 
 
</blockquote>
</details>

---

31. Explain the security models in S3 bucket.

![Easy](https://github.com/revaturelabs/interviewquestions/blob/dev/ComplexityTags/simple%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

- S3 bucket can be secured in two ways:
-	ACL (Access Control List)
ACL is used to manage the access of resources to buckets and objects. An object of each bucket is associated with ACL. It defines which AWS accounts have granted access and the type of access. When a user sends the request for a resource, then its corresponding ACL will be checked to verify whether the user has granted access to the resource or not. When you create a bucket, then Amazon S3 creates a default ACL which provides full control over the AWS resources.
-	Bucket Policies
Bucket policies are only applied to S3 buckets. Bucket policies define what actions are allowed or denied. Bucket policies are attached to the bucket, not to an S3 object but the permissions defined in the bucket policy are applied to all the objects in the S3 bucket.


</blockquote>
</details>

---

32. What is the default storage class in S3?

![Easy](https://github.com/revaturelabs/interviewquestions/blob/dev/ComplexityTags/simple%20(2).svg)

<details>
<summary> <b>Show Answer</b> </summary>

<blockquote>

- The default storage class is Standard Frequently Accessed.

</blockquote>
</details>

---